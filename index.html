<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Project Website for Learning Humanoid Arm Motion via Centroidal Momentum Regularized Multi-Agent Reinforcement Learning">
  <meta name="keywords" content="Humanoid, RL">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>

  <title>Learning Humanoid Arm Motion via Centroidal Momentum Regularized Multi-Agent Reinforcement Learning</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://hojae-io.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">Learning Humanoid Arm Motion via Centroidal Momentum Regularized
                                                   Multi-Agent Reinforcement Learning</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://hojae-io.github.io/">Ho Jae Lee</a><sup>1</sup>,</span>
            <span class="author-block">Se Hwan Jeon<sup>1</sup>,</span>
            <span class="author-block">Sangbae Kim<sup>1</sup>,</span>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Biomimetic Robotics Lab<br>
              Massachusetts Institute of Technology, MA, USA</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2507.04140"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=BNYML7QZyWQ"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/hojae-io/LearningHumanoidArmMotion-RAL2025-Code"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section pt-0">
  <div class="container is-max-desktop">
    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/BNYML7QZyWQ?autoplay=1&mute=1"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Humans naturally swing their arms during locomotion to regulate whole-body dynamics, reduce angular momentum, 
            and help maintain balance. 
            Inspired by this principle, we present a limb-level multi-agent reinforcement learning (RL) framework that 
            enables coordinated whole-body control of humanoid robots through emergent arm motion. 
            Our approach employs separate actor-critic structures for the arms and legs, trained with centralized critics 
            but decentralized actors that share only base states and centroidal angular momentum (CAM) observations, 
            allowing each agent to specialize in task-relevant behaviors through modular reward design.
            The arm agent guided by CAM tracking and damping rewards promotes arm motions that reduce overall angular 
            momentum and vertical ground reaction moments, contributing to improved balance during locomotion or under 
            external perturbations.
            Comparative studies with single-agent and alternative multi-agent baselines further validate the effectiveness 
            of our approach.
            Finally, we deploy the learned policy on the MIT Humanoid, achieving robust performance across diverse 
            locomotion tasks, including flat-ground walking, rough terrain traversal, and stair climbing.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h2 class="title is-3">Overview</h2>
        <div class="content">
          <embed src="./static/images/fig_overview.png" type="image/png" width="100%" height="400px" />
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Contributions</h2>
    <div class="content">
      <ul>
        <li>We introduce a CAM reward based on biomechanical studies of human walking, and find that it guides the emergence of natural arm swing for stable locomotion and effective push recovery for our policy.</li>
        <li>We propose a multi-agent RL framework employing separate actor-critic networks for the arms and legs, trained centrally but executed in a decentralized manner.</li>
        <li>We demonstrate the effectiveness and practicality of our controller by validating its performance on a humanoid platform, both in simulation and hardware experiments.</li>
      </ul>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Push Recovery</h2>
    <p class="has-text-centered">
      The learned policy enables the humanoid to effectively utilize arm motions to recover balance from torque disturbances.
    </p>

    <div class="columns is-centered mt-1">

      <div class="column is-half">
        <h4 class="subtitle is-4 has-text-centered">+ \(\tau_z\) torque disturbance</h4>
        
        <div class="content has-text-centered" style="margin-bottom: 1.5rem;">
          <video preload playsinline autoplay muted loop width="100%">
            <source src="./static/videos/Recovery_1.mp4" type="video/mp4">
          </video>
        </div>
        
        <div class="content has-text-centered" style="margin-bottom: 1.5rem;">
          <video preload playsinline autoplay muted loop width="100%">
            <source src="./static/videos/Recovery_2.mp4" type="video/mp4">
          </video>
        </div>
        
        <div class="content has-text-centered">
          <video preload playsinline autoplay muted loop width="100%">
            <source src="./static/videos/Recovery_3.mp4" type="video/mp4">
          </video>
        </div>
      </div>

      <div class="column is-half">
        <h4 class="subtitle is-4 has-text-centered">- \(\tau_z\) torque disturbance</h4>
        
        <div class="content has-text-centered" style="margin-bottom: 1.5rem;">
          <video preload playsinline autoplay muted loop width="100%">
            <source src="./static/videos/Recovery_4.mp4" type="video/mp4">
          </video>
        </div>
        
        <div class="content has-text-centered" style="margin-bottom: 1.5rem;">
          <video preload playsinline autoplay muted loop width="100%">
            <source src="./static/videos/Recovery_5.mp4" type="video/mp4">
          </video>
        </div>
        
        <div class="content has-text-centered">
          <video preload playsinline autoplay muted loop width="100%">
            <source src="./static/videos/Recovery_6.mp4" type="video/mp4">
          </video>
        </div>
      </div>

    </div> </div>
</section>

<script>
  document.addEventListener('DOMContentLoaded', function() {
    const videos = document.querySelectorAll('video');
    videos.forEach(video => {
      video.volume = 0.25; // Sets volume to 25% (0.0 is mute, 1.0 is full)
    });
  });
</script>

<script>
  document.addEventListener('DOMContentLoaded', function() {
    // Select all video elements on the page
    const videos = document.querySelectorAll('video');

    // Add event listeners to each video
    videos.forEach(video => {
      // Show controls when the mouse enters the video area
      video.addEventListener('mouseover', () => {
        video.controls = true;
      });

      // Hide controls when the mouse leaves the video area
      video.addEventListener('mouseout', () => {
        video.controls = false;
      });
    });
  });
</script>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{lee2025learning,
      title={Learning Humanoid Arm Motion via Centroidal Momentum Regularized Multi-Agent Reinforcement Learning},
      author={Lee, Ho Jae and Jeon, Se Hwan and Kim, Sangbae},
      journal={arXiv preprint arXiv:2507.04140},
      year={2025}
    }</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8 has-text-centered">
        <div class="content">
          <p>
            Website template modified from <a href="https://nerfies.github.io/">NeRFies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
